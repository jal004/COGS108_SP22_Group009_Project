{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [`X`] YES - make available\n",
    "* [  ] NO - keep private"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your overview here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Goldie Chu\n",
    "- Tram Bui\n",
    "- Justin Huang\n",
    "- Tiffany Cheng\n",
    "- Jason Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the United States of America, what is the annual impact of GDP per capita, inflation rate, unemployment rate, and interest rate on the New York Stock Exchange (NYSE) market from 1980 to 2016?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "\n",
    "## Background & Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The New York stock exchange, the largest and highly esteemed market in the world,  marks its origin back in the 18th century with the Buttonwood Agreement. [^1] This would formally create a system where trusted parties were able to buy and sell stock with security and serve the economy. Stock’s primary purpose in the economy is to provide companies with more capital, the government to collect taxes, and investors to make more money. Many factors can affect stock and its price; these are not limited to supply and demand, inflation, and economic strength. \n",
    "\n",
    "An economic factor that we want to analyze is inflation rate. Inflation rate is the rise in price of goods and services. In regards to its relationship with stock, higher inflation tends to lead to lower purchasing power and affects relationship between consumer and company, employer earnings and company capital. There is also an inverse relationship with unemployment rate and the economy, thus affecting the stock market negatively as well. A prime example is the Great Recession. As the employment rate increased drastically to 10% from 5%, stocks also fell by more than 50%. [^3]  However, the stock market relationship with the unemployment rate cannot be correlated since there is a history of economic expansion during high unemployment rate and high stock prices.\n",
    "\n",
    "A country’s Gross Domestic Product per capita (GDP) measures the economic output per person. The stock market can positively and negatively impact GDP. [^2]\n",
    "\n",
    "We decided to analyze inflation rate, GDP per capita, unemployment rate, and interest rate because of its large impact on the economy and as a result, the stock market as well. These factors are large indicators of a wealthy economy and how an economy is behaving at a certain time. Thus, we want to utilize these statistics from 1980 to 2016, a time period that contained large events in the economy such as the Great Recession. As we look into these factors prior to our data, we see that there is still no perfect formula to measure when the ideal time to purchase stocks are. This is why we are analyzing data on certain economic factors in order to view what relationships these factors have and discover, from the past, whether or not some economic variables influence the stock market greater than others. \n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "[^1]: NYSE. The History of NYSE, NYSE, https://www.nyse.com/history-of-nyse#:~:text=The%20New%20York%20Stock%20Exchange%20traces%20its%20origins%20to%20the,traded%20and%20established%20set%20commissions. \n",
    "\n",
    "[^2]: Brock, Thomas, and Pete Rathburn. “Per Capita GDP Definition.” Investopedia, Investopedia, 8 Feb. 2022, https://www.investopedia.com/terms/p/per-capita-gdp.asp#:~:text=Key%20Takeaways,a%20country%20by%20its%20population. \n",
    "\n",
    "[^3]: Ewing, Doug. “How Does Inflation Affect the Stock Market and Potential Strategies to Take with Your Clients.” Nationwide Financial, Nationwide, 6 Apr. 2022, https://blog.nationwidefinancial.com/markets-economy/economic-commentary/how-inflation-affects-the-stock-market/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team hypothesizes that when the United States’ economy is doing well, the stock market will also be doing well, as measured by its high prices and low volatility — volatility being price movement. Essentially, we foresee the two as having similar positive and negative cycles. When a country’s economy is flourishing, consumers will feel good about buying and investing, particularly for purchases like stocks; however, when a country’s economy is withering, consumers will worry about the lowering value in their investments and sell their stocks. When that recession hits, both the economy and the stock market will be low. \n",
    "\n",
    "More specifically, high GDP per capita, 2-5% inflation, low unemployment, and a lower interest rate will lead to growth, as measured by higher prices and lower volatility, in the New York Stock Exchange market. On the other hand, low GDP per capita, inflation above 10%, high unemployment, and a higher interest rate will lead to decline, as measured by lower prices and higher volatility, in the NYSE market. For one, we believe that rising stocks increase consumer confidence, which can lead to a higher GDP per capita since it is primarily driven by spending and investments, like buying into stocks. Then, we found that the Federal Reserve’s inflation target is 2% to ensure “maximum employment”, so our team decided that an inflation rate of 2-5% is good for the economy since more people are in employment, while anything above 10% is too much since it overly erodes the value of a dollar in earnings [^1] — essentially, low inflation might impact the stock market positively, whereas too much inflation will lead to greater volatile fluctuations in market prices. Similar to above, low unemployment may lead to a rise in stock price and stability given the positive status of the economy, while high unemployment may lead to a dip in stock price and stability given the negative status of the economy. And lastly, when the country's interest rate is too high, consumers have less disposable income for things like investments, which can equate to a less successful stock market. \n",
    "\n",
    "References: \n",
    "\n",
    "[^1]: Federal Reserve. “Federal Reserve Issues FOMC Statement.” Board of Governors of the Federal Reserve System, https://www.federalreserve.gov/newsevents/pressreleases/monetary20220316a.htm#:~:text=The%20Committee%20seeks%20to%20achieve,labor%20market%20to%20remain%20strong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Stock Exchange Data\n",
    "- Link to the dataset: https://www.kaggle.com/datasets/mattiuzc/stock-exchange-data\n",
    "- Number of observations: 112,458\n",
    "- Description of the dataset: This dataset provides stock exchanges from all around the world from 1965 to 2021. It contains opening price, highest price during trading day, lowest price during trading day, adjusted prices, and numbers of shares traded during day. \n",
    "\n",
    "## 2. GDP per Capita, Current Prices (U.S. Dollars per Capita)\n",
    "- Link to the dataset: https://www.imf.org/external/datamapper/NGDPDPC@WEO/OEMDC/ADVEC/WEOWORLD \n",
    "- Number of observations: 231 \n",
    "- Description of the dataset: This dataset provides the gross domestic product (GDP) per capita of all the countries in the world from 1980 to 2027. Any years after 2021 are expected values. We plan to combine this dataset with the ‘Michelin Guide Restaurants 2021’ dataset by merging the 2021 GDP column of countries to the above table. \n",
    "\n",
    "## 3. Inflation Rate, Average Consumer Prices\n",
    "- Link to the dataset: https://www.imf.org/external/datamapper/PCPIPCH@WEO/OEMDC/ADVEC/WEOWORLD \n",
    "- Number of observations: 229\n",
    "- Description of the dataset: This dataset provides the inflation rate of all the countries in the world from 1980 to 2027. Any years after 2021 are expected values. We plan to combine this dataset with the selected stock exchange dataset and American GDP dataset by again taking the American inflation rate and putting it into a table as a column.  \n",
    "\n",
    "## 4. Unemployment Rate\n",
    "- Link to the dataset: https://www.kaggle.com/datasets/axeltorbenson/unemployment-data-19482021\n",
    "- Number of observations: 888\n",
    "- Description of the dataset: This dataset provides the unemployment rate of all the countries in the world from 1948 to 2021. We plan to combine this dataset with all the previous datasets by merging the American unemployment rate as a column to the congregated table.  \n",
    "\n",
    "## 5. Federal Reserve Interest Rates, 1954-Present\n",
    "- Link to the dataset: https://www.kaggle.com/datasets/federalreserve/interest-rates \n",
    "- Number of observations: 905\n",
    "- Description of the dataset: This dataset provides the federal reserve interest rates set by Congress from 1954 to 2017. We plan to combine this dataset with all the above datasets by merging this entire dataset as an extra column to the overall table.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for performing numerical computations\n",
    "import numpy as np\n",
    "\n",
    "# Used for reading, modifying, and analyzing datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Disable pandas warnings during data cleaning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Both of these packages are used for visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining Relevant Function(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Numerical Values in the Datasets\n",
    "All of the numerical values in our datasets are string values and some of the datasets use commas to display larger values (e.g. one-thousand as 1,000). We wish to remove these commas and work with float values instead. \n",
    "\n",
    "This function will:\n",
    "1. Remove these commas from numerical values in the dataset, if present\n",
    "2. Convert the string values to float, or NaN otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_numbers(string):\n",
    "    string = string.strip()\n",
    "    \n",
    "    string = string.replace(',', '')\n",
    "    \n",
    "    string = string.strip()\n",
    "    \n",
    "    try:\n",
    "        float(string)\n",
    "    except:\n",
    "        output = np.nan\n",
    "    else:\n",
    "        output = float(string)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Importing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Exchange Data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Stock Exchange Data dataset into the 'stock' DataFrame\n",
    "# Dataset link: https://www.kaggle.com/datasets/mattiuzc/stock-exchange-data \n",
    "stock = pd.read_csv('stock_exchanges.csv')\n",
    "\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country GDP Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Country GDP dataset into the 'gdp' DataFrame\n",
    "# Dataset link: https://www.imf.org/external/datamapper/NGDPDPC@WEO/OEMDC/ADVEC/WEOWORLD\n",
    "gdp = pd.read_csv('all_country_gdp.csv')\n",
    "\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Inflation Rate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Country Inflation dataset into the 'inflation' DataFrame\n",
    "# Dataset link: https://www.imf.org/external/datamapper/PCPIPCH@WEO/OEMDC/ADVEC/WEOWORLD\n",
    "inflation = pd.read_csv('country_inflation.csv')\n",
    "\n",
    "inflation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country Unemployment Rate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Country Unemployment dataset into the 'unemployment' DataFrame\n",
    "# Dataset link: https://www.imf.org/external/datamapper/LUR@WEO/OEMDC/ADVEC/WEOWORLD\n",
    "unemployment = pd.read_csv('country_unemployment.csv')\n",
    "\n",
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federal Reserve Interest Rates Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Federal Reserve Interest Rates dataset into the 'interest' DataFrame\n",
    "# Dataset link: https://www.kaggle.com/datasets/federalreserve/interest-rates\n",
    "\n",
    "interest = pd.read_csv('interest_rates.csv')\n",
    "\n",
    "interest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one stock index dataset and four datasets on various US data. We are cleaning and standardizing each dataset separately and merging the four datasets on US data while keeping the stock index data separate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cleaning the Stock Exchange Data Dataset\n",
    "\n",
    "The goal of cleaning this dataset is to:\n",
    "1. Extract the maximum, minimum, and average price of each index in every year from 1980 to 2016\n",
    "2. Merge the extracted prices into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the desired years from each date in the dataset\n",
    "stock['Year'] = stock.Date.str.split('-').str[0]\n",
    "stock['Year'] = stock['Year'].astype(str).apply(standardize_numbers) # Standardizing the years\n",
    "stock = stock[(stock['Year'] >= 1980) & (stock['Year'] <= 2016)]\n",
    "\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Extracting the Maximum Price for Each Index in Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum price for each index in each year\n",
    "stock_max = stock.groupby(['Index', 'Year'], as_index=False).max()\n",
    "stock_max = stock_max[['Year', 'Index', 'Open', 'High', 'Low', 'Close']]\n",
    "stock_max = stock_max.rename(columns = {'Open': 'Max Open', 'High': 'Max High', 'Low':'Max Low', 'Close':'Max Close'})\n",
    "\n",
    "stock_max.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Extracting the Minimum Price for Each Index in Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum price for each index in each year\n",
    "stock_min = stock.groupby(['Index', 'Year'], as_index=False).min()\n",
    "stock_min = stock_min[['Year', 'Index', 'Open', 'High', 'Low', 'Close']]\n",
    "stock_min = stock_min.rename(columns = {'Open': 'Min Open', 'High': 'Min High', 'Low':'Min Low', 'Close':'Min Close'})\n",
    "\n",
    "stock_min.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Extracting the Average Price for Each Index in Each Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average price of every index in each year\n",
    "stock_avg = stock.groupby(['Index', 'Year'], as_index=False).mean()\n",
    "stock_avg = stock_avg[['Year', 'Index', 'Open', 'High', 'Low', 'Close']]\n",
    "stock_avg = stock_avg.rename(columns = {'Open': 'Avg Open', 'High': 'Avg High', 'Low':'Avg Low', 'Close':'Avg Close'})\n",
    "\n",
    "stock_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Merging the Extracted Price DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the DataFrames by the stock indexes and year\n",
    "stock_merge = stock_max.merge(stock_min, on=['Index', 'Year'])\n",
    "stock_merge = stock_merge.merge(stock_avg, on=['Index', 'Year'])\n",
    "\n",
    "# Rearranging the columns for readability: Max, Min, Avg for each price \n",
    "stock_merge = stock_merge.reindex(columns=['Year', 'Index', 'Max Open', 'Min Open', 'Avg Open', 'Max High', 'Min High', 'Avg High', 'Max Low', 'Min Low', 'Avg Low', 'Max Close', 'Min Close', 'Avg Close'])\n",
    "\n",
    "# Final result from cleaning\n",
    "stock_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Adding Percent Change in Average Close Price Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the percent change per year for each stock index\n",
    "stock_merge['% Change in Avg Close'] = stock_merge.groupby('Index', as_index=False)['Avg Close'].pct_change()\n",
    "\n",
    "# There is no percent change for the first price in each index which results in NaNs for these rows. Instead, we fill these values with 0\n",
    "stock_merge['% Change in Avg Close'] = stock_merge['% Change in Avg Close'].fillna(0)\n",
    "\n",
    "# Final result from cleaning\n",
    "stock_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning the Four US Data Datasets\n",
    "\n",
    "The goal of cleaning these datasets are: \n",
    "1. Clean each of the four datasets separately\n",
    "2. Merge each of the four datasets into a single DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Cleaning the Country GDP Dataset\n",
    "\n",
    "The goal of cleaning this dataset is to:\n",
    "1. Extract the US GDP values between 1980 to 2016\n",
    "2. Remove countries with a NaN value\n",
    "3. Standardize the 'Year' and 'US GDP' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the United States GDP values\n",
    "gdp = gdp.rename(columns={'GDP per capita, current prices\\n (U.S. dollars per capita)': 'Country'})\n",
    "gdp_sub = gdp[gdp['Country'] == 'United States']\n",
    "\n",
    "# Removing all countries with a NaN value\n",
    "gdp_sub.dropna(inplace=True)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "gdp_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Transposing the DataFrame\n",
    "gdp_sub = gdp_sub.melt( var_name=\"Year\", value_name = 'US GDP')\n",
    "gdp_sub = gdp_sub.drop(gdp_sub.index[0])\n",
    "\n",
    "# Standardizing the columns\n",
    "gdp_sub['Year'] = gdp_sub['Year'].astype(str).apply(standardize_numbers)\n",
    "gdp_sub['US GDP'] = gdp_sub['US GDP'].astype(str).apply(standardize_numbers)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "gdp_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Extracting years between 1980-2016\n",
    "gdp_sub = gdp_sub[gdp_sub['Year'] <= 2016]\n",
    "\n",
    "gdp_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Cleaning the Country Inflation Rate Dataset\n",
    "\n",
    "The goal of cleaning this dataset is to:\n",
    "1. Extract the US Inflation Rate values between 1980 to 2016\n",
    "2. Remove countries with a NaN value\n",
    "3. Standardize the 'Year' and 'US Inflation Rate' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the United States inflation rate values\n",
    "inflation = inflation.rename(columns={'Inflation rate, average consumer prices (Annual percent change)': 'Country'})\n",
    "inflation_sub = inflation[inflation['Country'] == 'United States']\n",
    "\n",
    "# Removing all countries with a NaN value\n",
    "inflation_sub.dropna(inplace=True)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "inflation_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Transposing the DataFrame\n",
    "inflation_sub = inflation_sub.melt( var_name=\"Year\", value_name = 'US Inflation Rate')\n",
    "inflation_sub = inflation_sub.drop(inflation_sub.index[0])\n",
    "\n",
    "# Standardizing the columns\n",
    "inflation_sub['Year'] = inflation_sub['Year'].astype(str).apply(standardize_numbers)\n",
    "inflation_sub['US Inflation Rate'] = inflation_sub['US Inflation Rate'].astype(str).apply(standardize_numbers)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "inflation_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Extracting years between 1980-2016\n",
    "inflation_sub = inflation_sub[inflation_sub['Year'] <= 2016]\n",
    "\n",
    "inflation_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Cleaning the Country Unemployment Rate Dataset\n",
    "\n",
    "The goal of cleaning this dataset is to:\n",
    "1. Extract the US Unemployment Rate values between 1980 to 2016\n",
    "2. Remove countries with a NaN value\n",
    "3. Standardize the 'Year' and 'US Unemployment' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only the United States unemployment rate values\n",
    "unemployment = unemployment.rename(columns={'Unemployment rate (Percent)': 'Country'})\n",
    "unemployment_sub = unemployment[unemployment['Country'] == 'United States']\n",
    "\n",
    "# Removing all countries with a NaN value\n",
    "unemployment_sub.dropna(inplace=True)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "unemployment_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Transposing the DataFrame\n",
    "unemployment_sub = unemployment_sub.melt( var_name=\"Year\", value_name = 'US Unemployment')\n",
    "unemployment_sub = unemployment_sub.drop(unemployment_sub.index[0])\n",
    "\n",
    "# Standardizing the columns\n",
    "unemployment_sub['Year'] = unemployment_sub['Year'].astype(str).apply(standardize_numbers)\n",
    "unemployment_sub['US Unemployment'] = unemployment_sub['US Unemployment'].astype(str).apply(standardize_numbers)\n",
    "\n",
    "# Reset indices after dropping NaN values\n",
    "unemployment_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Extracting years between 1980-2016\n",
    "unemployment_sub = unemployment_sub[unemployment_sub['Year'] <= 2016]\n",
    "\n",
    "unemployment_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Cleaning the Federal Reserve Interest Rates Dataset\n",
    "\n",
    "The goal of cleaning this dataset is to:\n",
    "1. Extract the average effective federal funds rate between 1980 to 2016\n",
    "2. Extract the average percent change in real GDP between 1980 to 2016\n",
    "3. Standardize the extracted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the average of the desired values in each year\n",
    "interest_sub = interest.groupby('Year', as_index=False)[['Effective Federal Funds Rate', 'Real GDP (Percent Change)']].mean()\n",
    "\n",
    "# Standardizing the years between 1980-2016\n",
    "interest_sub['Year'] = interest_sub['Year'].astype(str).apply(standardize_numbers)\n",
    "interest_sub = interest_sub[(interest_sub['Year'] >= 1980) & (interest_sub['Year'] <= 2016)]\n",
    "\n",
    "# Resetting the indices\n",
    "interest_sub.reset_index(inplace=True, drop=True)\n",
    "\n",
    "interest_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Merging the US Data Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the four cleaned US Data DataFrames\n",
    "us_data_merge = gdp_sub.merge(inflation_sub, on='Year')\n",
    "us_data_merge = us_data_merge.merge(unemployment_sub, on='Year')\n",
    "us_data_merge = us_data_merge.merge(interest_sub, on='Year')\n",
    "\n",
    "# Final result from cleaning\n",
    "us_data_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the five datasets, we have two DataFrames: one containing the stock index data (stock_merge), and one containing the US data (us_data_merge). Additionally, the numerical values in each DataFrame are floats and the stock index values are strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result of the stock index DataFrame\n",
    "stock_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock index DataFrame types\n",
    "stock_merge.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result of the US data DataFrame\n",
    "us_data_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US data DataFrame types\n",
    "us_data_merge.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Stock Index Data: Average Opening and Closing Prices per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics on the relevant subset of the stock index DataFrame for each stock index\n",
    "stock_merge.groupby('Index')[['Avg Open', 'Avg Close']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Stock Index Data: Average High and Low Prices per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics on the relevant subset of the stock index DataFrame for each stock index\n",
    "stock_merge.groupby('Index')[['Avg High', 'Avg Low']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. US Data from 1980 to 2016 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics on the relevant subset of the US data DataFrame\n",
    "us_data_merge[['US GDP', 'US Inflation Rate', 'US Unemployment', 'Effective Federal Funds Rate', 'Real GDP (Percent Change)']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identifying Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Stock Index Data: Percent Change in Average Closing Price per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of % Change in Avg Close\n",
    "stock_merge[stock_merge['% Change in Avg Close'] == stock_merge['% Change in Avg Close'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of % Change in Avg Close\n",
    "stock_merge[stock_merge['% Change in Avg Close'] == stock_merge['% Change in Avg Close'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. US Data from 1980 to 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. US GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of US GDP\n",
    "us_data_merge[us_data_merge['US GDP'] == us_data_merge['US GDP'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of US GDP\n",
    "us_data_merge[us_data_merge['US GDP'] == us_data_merge['US GDP'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. US Inflation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of US Inflation Rate\n",
    "us_data_merge[us_data_merge['US Inflation Rate'] == us_data_merge['US Inflation Rate'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of US Inflation Rate\n",
    "us_data_merge[us_data_merge['US Inflation Rate'] == us_data_merge['US Inflation Rate'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. US Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of US Unemployment\n",
    "us_data_merge[us_data_merge['US Unemployment'] == us_data_merge['US Unemployment'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of US Unemployment\n",
    "us_data_merge[us_data_merge['US Unemployment'] == us_data_merge['US Unemployment'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Effective Federal Funds Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of US Effective Federal Funds Rate\n",
    "us_data_merge[us_data_merge['Effective Federal Funds Rate'] == us_data_merge['Effective Federal Funds Rate'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of US Effective Federal Funds Rate\n",
    "us_data_merge[us_data_merge['Effective Federal Funds Rate'] == us_data_merge['Effective Federal Funds Rate'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### e. Percent Change in Real GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum of Real GDP (Percent Change)\n",
    "us_data_merge[us_data_merge['Real GDP (Percent Change)'] == us_data_merge['Real GDP (Percent Change)'].min()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum of Real GDP (Percent Change)\n",
    "us_data_merge[us_data_merge['Real GDP (Percent Change)'] == us_data_merge['Real GDP (Percent Change)'].max()].reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots bigger\n",
    "sns.set(rc = {'figure.figsize':(25,10)}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Stock Index Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Average Closing Price of Each Stock Index Between 1980 to 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average closing price of each stock index\n",
    "avg_close = sns.lineplot(data=stock_merge, x='Year', y='Avg Close', hue='Index')\n",
    "avg_close.set_title('Average Closing Price of Each Stock Index Between 1980 to 2016', fontsize=22)\n",
    "\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Percent Change in Average Closing Price for Each Stock Index Between 1980-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent change in average closing price for each stock index\n",
    "pct_avg_close = sns.lineplot(data=stock_merge, x='Year', y='% Change in Avg Close', hue='Index')\n",
    "pct_avg_close.set_title('% Change in Average Closing Price of Each Stock Index Between 1980 to 2016', fontsize=22)\n",
    "\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Price Range for Each Stock Index Between 1980-2016\n",
    "\n",
    "The price range of each stock index in displayed through a min-max-mean line plot. For better visual clarity, we have plotted each of the indexes in groups of 3-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Stock Indexes: 000001.SS vs. NYA vs. GDAXI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 000001.SS Index\n",
    "ss = stock_merge[stock_merge['Index'] == '000001.SS']\n",
    "ss.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ss_years = ss['Year'].tolist()\n",
    "ss_min_close = ss['Min Close'].tolist()\n",
    "ss_max_close = ss['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=ss_years, y1=ss_max_close, y2=ss_min_close, color='lightsteelblue', alpha=0.4)\n",
    "\n",
    "ss_avg_close = sns.lineplot(data=ss, x='Year', y='Avg Close', label='000001.SS')\n",
    "\n",
    "# NYA Index\n",
    "nya = stock_merge[stock_merge['Index'] == 'NYA']\n",
    "nya.reset_index(inplace=True, drop=True)\n",
    "\n",
    "nya_years = nya['Year'].tolist()\n",
    "nya_min_close = nya['Min Close'].tolist()\n",
    "nya_max_close = nya['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=nya_years, y1=nya_max_close, y2=nya_min_close, color='burlywood', alpha=0.4)\n",
    "\n",
    "nya_avg_close = sns.lineplot(data=nya, x='Year', y='Avg Close', label='NYA')\n",
    "\n",
    "# GDAXI Index\n",
    "gdaxi = stock_merge[stock_merge['Index'] == 'GDAXI']\n",
    "gdaxi.reset_index(inplace=True, drop=True)\n",
    "\n",
    "gdaxi_years = gdaxi['Year'].tolist()\n",
    "gdaxi_min_close = gdaxi['Min Close'].tolist()\n",
    "gdaxi_max_close = gdaxi['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=gdaxi_years, y1=gdaxi_max_close, y2=gdaxi_min_close, color='darkseagreen', alpha=0.4)\n",
    "\n",
    "gdaxi_avg_close = sns.lineplot(data=gdaxi, x='Year', y='Avg Close', label='GDAXI')\n",
    "\n",
    "# Legend\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)\n",
    "\n",
    "# Title\n",
    "gdaxi_avg_close.set_title('Min-Max-Mean Plots for Stock Indexes: 000001.SS, NYA, and GDAXI', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Stock Indexes: GSPTSE vs. HSI vs. IXIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSPTSE Index\n",
    "gsptse = stock_merge[stock_merge['Index'] == 'GSPTSE']\n",
    "gsptse.reset_index(inplace=True, drop=True)\n",
    "\n",
    "gsptse_years = gsptse['Year'].tolist()\n",
    "gsptse_min_close = gsptse['Min Close'].tolist()\n",
    "gsptse_max_close = gsptse['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=gsptse_years, y1=gsptse_max_close, y2=gsptse_min_close, color='lightsteelblue', alpha=0.4)\n",
    "\n",
    "gsptse_avg_close = sns.lineplot(data=gsptse, x='Year', y='Avg Close', label='GSPTSE')\n",
    "\n",
    "# HSI Index\n",
    "hsi = stock_merge[stock_merge['Index'] == 'HSI']\n",
    "hsi.reset_index(inplace=True, drop=True)\n",
    "\n",
    "hsi_years = hsi['Year'].tolist()\n",
    "hsi_min_close = hsi['Min Close'].tolist()\n",
    "hsi_max_close = hsi['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=hsi_years, y1=hsi_max_close, y2=hsi_min_close, color='burlywood', alpha=0.4)\n",
    "\n",
    "hsi_avg_close = sns.lineplot(data=hsi, x='Year', y='Avg Close', label='HSI')\n",
    "\n",
    "# IXIC Index\n",
    "ixic = stock_merge[stock_merge['Index'] == 'IXIC']\n",
    "ixic.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ixic_years = ixic['Year'].tolist()\n",
    "ixic_min_close = ixic['Min Close'].tolist()\n",
    "ixic_max_close = ixic['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=ixic_years, y1=ixic_max_close, y2=ixic_min_close, color='darkseagreen', alpha=0.4)\n",
    "\n",
    "ixic_avg_close = sns.lineplot(data=ixic, x='Year', y='Avg Close', label='IXIC')\n",
    "\n",
    "# Legend\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)\n",
    "\n",
    "# Title\n",
    "ixic_avg_close.set_title('Min-Max-Mean Plots for Stock Indexes: GSPTSE, HSI, and IXIC', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c. Stock Indexes: NSEI, SSMI, and TWII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSEI Index\n",
    "nsei = stock_merge[stock_merge['Index'] == 'NSEI']\n",
    "nsei.reset_index(inplace=True, drop=True)\n",
    "\n",
    "nsei_years = nsei['Year'].tolist()\n",
    "nsei_min_close = nsei['Min Close'].tolist()\n",
    "nsei_max_close = nsei['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=nsei_years, y1=nsei_max_close, y2=nsei_min_close, color='lightsteelblue', alpha=0.4)\n",
    "\n",
    "nsei_avg_close = sns.lineplot(data=nsei, x='Year', y='Avg Close', label='NSEI')\n",
    "\n",
    "# SSMI Index\n",
    "ssmi = stock_merge[stock_merge['Index'] == 'SSMI']\n",
    "ssmi.reset_index(inplace=True, drop=True)\n",
    "\n",
    "ssmi_years = ssmi['Year'].tolist()\n",
    "ssmi_min_close = ssmi['Min Close'].tolist()\n",
    "ssmi_max_close = ssmi['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=ssmi_years, y1=ssmi_max_close, y2=ssmi_min_close, color='burlywood', alpha=0.4)\n",
    "\n",
    "ssmi_avg_close = sns.lineplot(data=ssmi, x='Year', y='Avg Close', label='SSMI')\n",
    "\n",
    "# TWII Index\n",
    "twii = stock_merge[stock_merge['Index'] == 'TWII']\n",
    "twii.reset_index(inplace=True, drop=True)\n",
    "\n",
    "twii_years = twii['Year'].tolist()\n",
    "twii_min_close = twii['Min Close'].tolist()\n",
    "twii_max_close = twii['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=twii_years, y1=twii_max_close, y2=twii_min_close, color='darkseagreen', alpha=0.4)\n",
    "\n",
    "twii_avg_close = sns.lineplot(data=twii, x='Year', y='Avg Close', label='TWII')\n",
    "\n",
    "# Legend\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)\n",
    "\n",
    "# Title\n",
    "twii_avg_close.set_title('Min-Max-Mean Plots for Stock Indexes: NSEI, SSMI, and TWII', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d. Stock Indexes: J203.JO, N100, N225, and 399001.SZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# J203.JO Index\n",
    "j203 = stock_merge[stock_merge['Index'] == 'J203.JO']\n",
    "j203.reset_index(inplace=True, drop=True)\n",
    "\n",
    "j203_years = j203['Year'].tolist()\n",
    "j203_min_close = j203['Min Close'].tolist()\n",
    "j203_max_close = j203['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=j203_years, y1=j203_max_close, y2=j203_min_close, color='lightsteelblue', alpha=0.4)\n",
    "\n",
    "j203_avg_close = sns.lineplot(data=j203, x='Year', y='Avg Close', label='J203.JO')\n",
    "\n",
    "# N100 Index\n",
    "n100 = stock_merge[stock_merge['Index'] == 'N100']\n",
    "n100.reset_index(inplace=True, drop=True)\n",
    "\n",
    "n100_years = n100['Year'].tolist()\n",
    "n100_min_close = n100['Min Close'].tolist()\n",
    "n100_max_close = n100['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=n100_years, y1=n100_max_close, y2=n100_min_close, color='burlywood', alpha=0.4)\n",
    "\n",
    "n100_avg_close = sns.lineplot(data=n100, x='Year', y='Avg Close', label='N100')\n",
    "\n",
    "# N225 Index\n",
    "n225 = stock_merge[stock_merge['Index'] == 'N225']\n",
    "n225.reset_index(inplace=True, drop=True)\n",
    "\n",
    "n225_years = n225['Year'].tolist()\n",
    "n225_min_close = n225['Min Close'].tolist()\n",
    "n225_max_close = n225['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=n225_years, y1=n225_max_close, y2=n225_min_close, color='darkseagreen', alpha=0.4)\n",
    "\n",
    "n225_avg_close = sns.lineplot(data=n225, x='Year', y='Avg Close', label='N225')\n",
    "\n",
    "# 399001.SZ Index\n",
    "sz = stock_merge[stock_merge['Index'] == '399001.SZ']\n",
    "sz.reset_index(inplace=True, drop=True)\n",
    "\n",
    "sz_years = sz['Year'].tolist()\n",
    "sz_min_close = sz['Min Close'].tolist()\n",
    "sz_max_close = sz['Max Close'].tolist()\n",
    "\n",
    "plt.fill_between(x=sz_years, y1=sz_max_close, y2=sz_min_close, color='salmon', alpha=0.4)\n",
    "\n",
    "sz_avg_close = sns.lineplot(data=sz, x='Year', y='Avg Close', label='399001.SZ')\n",
    "\n",
    "# Legend\n",
    "plt.legend(title='Stock Index', loc='upper left', fontsize=16, title_fontsize=18)\n",
    "\n",
    "# Title\n",
    "n225_avg_close.set_title('Min-Max-Mean Plots for Stock Indexes: J203.JO, N100, N225, and 399001.SZ', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. US Data between 1980 to 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Placeholder Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team sees no issues with privacy or terms of agreement because no personal information was used in this study. Only annual data on economic and stock trends for the United States were presented. That also leads to a lack of biases on our part since we are not focusing on populations of people or predicting outcomes for the future. This study was only executed out of curiosity to see the relationships between the American economy and NYSE stock market. However, we do realize that there may be the possibility for an outside individual to use our data to gather information to actually predict trends in the stock market. That becomes a possible ethical issue since the ability to predict stock market trends will most likely be used for inequitable gain and nefarious purposes, instead of being a free tool for everyone to use. This could become an unintended consequence of our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Goldie Chu: Finding data, Hypothesis, Ethics, and Privacy \n",
    "- Tram Bui: Background & Prior Work\n",
    "- Justin Huang: Finding data, Cleaning \n",
    "- Tiffany Cheng: Data visualization\n",
    "- Jason Lee: Cleaning, EDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
